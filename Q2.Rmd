---
title: "twitter"
author: "Dar Nettler & Carmela Davidovsky"
date: "December 18, 2017"
output: html_document
---
Install relevant packages
```{r}
install.packages("twitteR")
install.packages("httr")
install.packages("base64enc")
install.packages("jsonlite")
install.packages("wordcloud")
install.packages("tm")
install.packages("stringr")
install.packages("igraph")
install.packages("digest")
install.packages("rgl")
```

Loading relevant packages: 
```{r}
library(twitteR)
library(httr)
library(jsonlite)
library(tm)
library(stringr)
library(igraph)
library(digest)
library(rgl)
```

```{r}
#start the authorisation process
myapp = oauth_app("twitter", key="h055FoysHKU57ryKbIZvMVwaC", secret="7gbAzHv5dmeaVhOusLqQw9lm7MV8CznrUBZRd0fT0qw4UVbZbL")

#sign using token and token secret
sig1 = sign_oauth1.0(myapp, token="2268807271-b0r3vOtx98FzXBSSXP4xSTcP0muQPkHE7j7JWFQ", token_secret="djF1urmuH1xQ7BUcOIXvcHEZzGyWQiuxxgdX9aKPWgCrp")
```

```{r}
#set oauth
sig <- setup_twitter_oauth("h055FoysHKU57ryKbIZvMVwaC", "7gbAzHv5dmeaVhOusLqQw9lm7MV8CznrUBZRd0fT0qw4UVbZbL", "2268807271-b0r3vOtx98FzXBSSXP4xSTcP0muQPkHE7j7JWFQ", "djF1urmuH1xQ7BUcOIXvcHEZzGyWQiuxxgdX9aKPWgCrp")
```


Since we’re both regular watchers and fans of grey’s anatomy, we decided to continue with the theme of grey’s anatomy in this part of the assignment.

Using twitter’s API we requested 1,500 tweets that include the hashtag “#GreysAnatomy”.
Then, we extracted the hashtags from each tweet using the “stringr” package and regex in order to see what people are associating with the show  
Our graph consist of the hashtags from the extracted tweets as vertices. Two vertices share an edge if both hashtags appeared in the same tweet

For example: if the fallowing tweet was extracted:  
**the hottest guys in #GreysAnatomy are #McDreamy #McSteamy #McVet**    
the graph vertices will be: McDreamy, McSteamy and McVet  
and the graph edges: McDreamy--McSteamy, McDreamy—McVet McSteamy--McVet

```{r}

res<-searchTwitter("#GreysAnatomy",n=1500, lang = "en")
#res<-res2
temp<-list()
hashtags<-c()
left<-c()
right<-c()
not<-c("#GreysAnatomy")

#go over each tweet
for(i in 1:1500){
  #extract all of the tweet's hashtags
  w<-res[[i]]$text
  temp[i]<-str_extract_all(w,"#\\S+")
  #add the hashtags to a vector, not including "#GreysAnatomy"
  for(j in 1:length(temp[[i]])){
        hashtags<-c(hashtags,temp[[i]][j])
        hashtags<-hashtags[!hashtags %in% not]
  }
  #create the egdes of the graph
  if(length(hashtags)!=0){
  for(j in 1:length(hashtags))
    for(k in 1:length(hashtags))
        if(j<k){
          left<-c(left,hashtags[j])
          right<-c(right,hashtags[k])
        }
  }
  #reset vector for next tweet
  hashtags<-c()
}

#create data frame
df<-data.frame(left,right)
df<-df[!duplicated(df),]
write.csv(df,file="1500.csv",row.names = FALSE)
    
```
creating and displaying the graph
```{r}
readddd<-read.csv("1500.csv",header=T)
graphy<-graph.data.frame(readddd,directed = F)
#E(graphy)<-E(graphy) %>% unique()
V(graphy)$name
#degree(graphy)
V(graphy)$size<-degree(graphy)
V(graphy)$label<-NA
plot(graphy, margin=-0.1)
#tkplot(graphy,layout=layout.kamada.kawai)

```

betweeness
```{r}
which.max(betweenness(graphy, v=V(graphy), directed = FALSE, weights=NULL, nobigint = FALSE, normalized = FALSE))
```

closeness
```{r}
which.max(closeness(graphy, v=V(graphy), mode = c("out", "in", "all", "total"),
  weights = NULL, normalized = FALSE))
```

eigenvector
```{r}
which.max(eigen_centrality(graphy)$vector)
```

_________________

##Girvan-Newman community detection

This is a divisive method that works on undirected unweighted networks. It is based on calculating for each edge its **edge betweeness-** the number of shortest path going through this edge.

It then iteratively removes the edge with the highest betweeness score, until reaching some threshold.

The remaining connected vertices are communities (clusters).
```{r}
gc <-  edge.betweenness.community(graphy)
```

```{r}
#Store cluster ids for each vertex
memb <- membership(gc)
head(memb)
```

```{r}
plot(graphy, vertex.size=5, #vertex.label=NA,
     vertex.color=memb, asp=FALSE)
```

```{r}
gc
sizes(gc)
```

```{r}
#modularity for each phase of the previous algorithm
max(gc$modularity)
```


```{r}
# Remove self-loops is exist
graphy <- simplify(graphy)
gc2 <-  fastgreedy.community(graphy)
```

```{r}
plot(graphy,  vertex.size=5,
     vertex.color=membership(gc2), asp=FALSE)
```

```{r}
gc2
sizes(gc2)
max(gc2$modularity)
```
